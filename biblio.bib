% book
% Required fields: author or editor, title, publisher, year. 
% Optional fields: volume or number, series, address, edition, month, note.
@book{coulouris,
  author = {Coulouris  G.  F.,  Dollimore J. e  Kindberg T},
  title = {Distributed Systems: concepts and Design},
  publisher = {Addison-Wesley},
  year = {1994},
  edition = "second edition"

}

% article
% Required fields: author, title, journal, year. 
% Optional fields: volume, number, pages, month, note.
@article{donoho,
  author = {Donoho D. L.},
  title = {Compressed Sensing},
  journal = {IEEE Trans. Inf. Theory},
  volume = {52},
  number = {4},
  pages = {1289-1306},
  year = {2006}
}

% conference
% same as inproceedings
% Required fields: author, title, booktitle, year. 
% Optional fields: editor, volume or number, series, pages, address, month, organization, publisher, note
@conference{dalal,
  author = {Dalal N., Triggs B.},
  title = {Histograms of Oriented Gradients for Human Detection},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  address = {San Diego, USA},
  year = {2005},
  month = {20-26 June},
  pages = {886-893}
}

% website
% as misc
% Required fields: none. 
% Optional fields: author, title, howpublished, month, year, note.

@misc{edgeimpulse_syntiant_tinyml,
  title={Edge Impulse Syntiant TinyML Deploying},
  author = {Edge Impulse},
  howpublished={https://docs.edgeimpulse.com/docs/edge-ai-hardware/mcu-+-ai-accelerators/syntiant-tinyml-board},
  note={Last Access 06/05/2025}
}
@misc{nodejs_repository,
  title={Node Js Repository},
  howpublished={deb.nodesource.com},
  note={Last Access 06/05/2025}
}

@misc{edgeimpulse_kws_example,
  title={Keyword Spotting on Syntiant Stop/Go Example by Edge Impulse},
  author = {Edge Impulse},
  url = {https://docs.edgeimpulse.com/docs/run-inference/hardware-specific-tutorials/responding-to-your-voice-syntiant-rc-commands-go-stop},
  note={Last Access 06/05/2025}
}

@misc{edgeimpulse_dataset_499022,
    title={Audio Classification - Keyword Spotting},
    author={Edge Impulse},
    year={2024},
    howpublished={https://studio.edgeimpulse.com/public/499022/latest},
    note={Apache 2.0, Last Access 06/05/2025}
}

@misc{esp32documentation,
  title={ESP32 Documentation},
  author={Espressif},
  howpublished={https://www.espressif.com/sites/default/files/documentation/esp32\_datasheet\_en.pdf},
  note={Last Access 06/05/2025},
  year={2025}, 
  note={Last Access 06/05/2025}
}

@misc{syntiant_tutorial_edgeimpulse,
  title={Syntiant Tutorial Edge Impulse},
  author={Syntiant},
  howpublished = {https://www.eetree.cn/wiki/\_media/syntiant\_tinyml\_tutorial\_mac\_.pdf},
  year={2021},
  note={Last Access 06/05/2025}
} 

@misc{tinyML_2021_summit, 
  title={TinyML 2021 Summit Presentation Syntiant NDP120},
  author={TinyML},
  howpublished={https://cms.tinyml.org/wp-content/uploads/summit2021/tinyMLSummit2021d1\_Awards\_Syntiant.pdf},
  year={2021},
  note={Last Access 06/05/2025}
}

@misc{experimental_try_on_ndp101, 
  title={NDP101 Experimental Implementation on NDP101},
  author={Christian, Neuhaus},
  howpublished={https://44-2.de/syntiant-ndp-101-always-on-low-power-speech-recognition/},
  year={2022},
  note={No other resources that corroborates data listed, Last Access 06/05/2025}
}

@misc{origin_code_1,
  title={Code Experimental Implementation on NDP101},
  author={Christian, Neuhaus},
  publisher={Github},
  howpublished = {https://github.com/happychriss/Goodwatch\_NDP101\_SpeeechRecognition/tree/master/include},
  year={2021},
  note={Last Access 06/05/2025}
}
@misc{analysis_syntiant_performances,
  title={The Intelligence of Things enabled by Syntiant's TinyML board},
  author={Alireza Yousefi, Luiz Franca-Neto, Will McDonald, Atul Gupta, Mallik Moturi, and David Garrett},
  publisher={Syntiant},
  note={Last Access 06/05/2025}
}

@misc{description_ndp101,
  title={General Description of NDP101 device},
  author={Syntiant},
  howpublished = {https://www.syntiant.com/ndp101\#data\_sheet},
  note={Last Access 06/05/2025}
}

@misc{PDM_module, 
  title={Understanding PDM Digital Audio},
  author={Thomas, Kite}, 
  publisher={Audio Precision, Inc.},
  howpublished = {https://users.ece.utexas.edu/~bevans/courses/rtdsp/lectures/10\_Data\_Conversion/AP\_Understanding\_PDM\_Digital\_Audio.pdf},
  year={2012},
  note={Last Access 06/05/2025}
}

@misc{edgeimpulse_firmware_syntiant,
  title={Firmware Syntiant TinyML Github Repository},
  author={Edge Impulse},
  year={2025},
  publisher={Github},
  howpublished = {https://github.com/edgeimpulse/firmware-syntiant-tinyml/tree/master},
  note={Last Access 06/05/2025}
}

@misc{edgeimpulse_processing_blocks,
  title={Edge Impulse Block Processing Repository},
  author={Edge Impulse},
  publisher={Github},
  year={2025},
  howpublished={https://github.com/edgeimpulse/processing-blocks},
  note={Last Access 06/05/2025}
}

@book{audio_processing_theory,
  author = {Tak, Rishabh and Agrawal, Dharmesh and Patil, Hemant},
  year = {2017},
  month = {11},
  pages = {317-325},
  title = {Novel Phase Encoded Mel Filterbank Energies for Environmental Sound Classification},
  isbn = {978-3-319-69899-1},
  doi = {10.1007/978-3-319-69900-4_40},
  howpublished={https://www.researchgate.net/publication/320733074_Novel_Phase_Encoded_Mel_Filterbank_Energies_for_Environmental_Sound_Classification}
}

@misc{syntiant_audio_block,
  title={Audio Syntiant},
  author={Edge Impulse},
  howpublished = {https://docs.edgeimpulse.com/docs/edge-impulse-studio/processing-blocks/audio-syntiant},
  note={Last Access 06/05/2025}
}

@misc{neural_network_training,
  title={TinyML on-device neural network training},
  author={Eugeniu, Ostrovan},
  year={2021-2022},
  howpublished={https://www.politesi.polimi.it/retrieve/e9f5774c-592d-4741-a6d4-82f5e501630e/TinyML\_on\_device\_neural\_network\_training%20fin.pdf},
  note={Last Access 06/05/2025}
}

@misc{types_impulses,
  title={Combining Impulses},
  author={Edge Impulse},
  howpublished={https://docs.edgeimpulse.com/docs/tips-and-tricks/combine-impulses},
  note={Last Access 06/05/2025}
}


@article{dnn_speaker_verification,
	abstract = {Speaker identification is a classification task which aims to identify a subject from a given time-series sequential data. Since the speech signal is a continuous one-dimensional time series, most of the current research methods are based on convolutional neural network (CNN) or recurrent neural network (RNN). Indeed, these methods perform well in many tasks, but there is no attempt to combine these two network models to study the speaker identification task. Due to the spectrogram that a speech signal contains, the spatial features of voiceprint (which corresponds to the voice spectrum) and CNN are effective for spatial feature extraction (which corresponds to modeling spectral correlations in acoustic features). At the same time, the speech signal is in a time series, and deep RNN can better represent long utterances than shallow networks. Considering the advantage of gated recurrent unit (GRU) (compared with traditional RNN) in the segmentation of sequence data, we decide to use stacked GRU layers in our model for frame-level feature extraction. In this paper, we propose a deep neural network (DNN) model based on a two-dimensional convolutional neural network (2-D CNN) and gated recurrent unit (GRU) for speaker identification. In the network model design, the convolutional layer is used for voiceprint feature extraction and reduces dimensionality in both the time and frequency domains, allowing for faster GRU layer computation. In addition, the stacked GRU recurrent network layers can learn a speaker's acoustic features. During this research, we tried to use various neural network structures, including 2-D CNN, deep RNN, and deep LSTM. The above network models were evaluated on the Aishell-1 speech dataset. The experimental results showed that our proposed DNN model, which we call deep GRU, achieved a high recognition accuracy of 98.96%. At the same time, the results also demonstrate the effectiveness of the proposed deep GRU network model versus other models for speaker identification. Through further optimization, this method could be applied to other research similar to the study of speaker identification.},
	article-number = {3603},
	author = {Ye, Feng and Yang, Jun},
	doi = {10.3390/app11083603},
	issn = {2076-3417},
	journal = {Applied Sciences},
	number = {8},
	title = {A Deep Neural Network Model for Speaker Identification},
	url = {https://www.mdpi.com/2076-3417/11/8/3603},
	volume = {11},
	year = {2021},
	bdsk-url-1 = {https://www.mdpi.com/2076-3417/11/8/3603},
	bdsk-url-2 = {https://doi.org/10.3390/app11083603},
  howpublished={https://www.mdpi.com/2076-3417/11/8/3603},
  note={Last Access 06/05/2025}
}

@article{dvector_extractor_TinySV,
  author = {Pavan, Massimo and Mombelli, Gioele and Sinacori, Francesco and Roveri, Manuel},
  title = {TinySV: Speaker Verification in TinyML with On-device Learning},
  year = {2025},
  isbn = {9798400711619},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3703412.3703415},
  doi = {10.1145/3703412.3703415},
  abstract = {TinyML is a novel area of machine learning that gained huge momentum in the last few years thanks to the ability to execute machine learning algorithms on tiny devices (such as Internet-of-Things or embedded systems). Interestingly, research in this area focused on the efficient execution of the inference phase of TinyML models on tiny devices, while very few solutions for on-device learning of TinyML models are available in the literature due to the relevant overhead introduced by the learning algorithms.The aim of this paper is to introduce a new type of adaptive TinyML solution that can be used in tasks, such as the presented Tiny Speaker Verification (TinySV), that require to be tackled with an on-device learning algorithm. Achieving this goal required (i) reducing the memory and computational demand of TinyML learning algorithms, and (ii) designing a TinyML learning algorithm operating with few and possibly unlabelled training data. The proposed TinySV solution relies on a two-layer hierarchical TinyML solution comprising Keyword Spotting and Adaptive Speaker Verification module. We evaluated the effectiveness and efficiency of the proposed TinySV solution on a dataset collected expressly for the task and tested the proposed solution on a real-world IoT device (Infineon PSoC 62S2 Wi-Fi BT Pioneer Kit).},
  booktitle = {Proceedings of the 4th International Conference on AI-ML Systems},
  articleno = {2},
  numpages = {10},
  keywords = {TinyML, EmbeddedML, On-device Learning, Speaker Verification, Keyword Spotting},
  location = {
  },
  howpublished={https://dl.acm.org/doi/full/10.1145/3703412.3703415},
  series = {AIMLSystems '24},
  note={Last Access 07/05/2025}
}

@misc{hardware_ndp101,
  title={hardware\_ndp101},
  author={Syntiant},
  howpublished = {https://www.syntiant.com/hardware},
  note={Last Access 07/05/2025}
}

@misc{dvector_extractor_code,
  title={TinySV D-vector Extractor Github Reference},
  author={Pavan, Massimo and Mombelli, Gioele and Sinacori, Francesco and Roveri, Manuel},
  year={2023},
  howpublished = {https://github.com/AI-Tech-Research-Lab/TinySV},
  note={Last Access 07/05/2025}
}

@article{speechcommands, 
  title={Speech Commands: A public dataset for single-word speech recognition.},
  author={Warden, Pete},
  howpublished={http://download.tensorflow.org/data/speech\_commands\_v0.01.tar.gz},
  year={2017},
  note={Last Access 07/05/2025}
}

@misc{netron,
  title={Netron.app Tool for Model Representation},
  author={Lutz Roeder},
  howpublished = {https://netron.app},
  note={Last Access 07/05/2025}
}

@book{distillation_from_cnn_to_dnn,
  author={Liu, Ying and Song, Yan and McLoughlin, Ian and Liu, Lin and Dai, Li-rong},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={An Effective Deep Embedding Learning Method Based on Dense-Residual Networks for Speaker Verification}, 
  year={2021},
  volume={},
  number={},
  pages={6683-6687},
  keywords={Learning systems;Convolution;Conferences;Acoustics;Complexity theory;Speech processing;Residual neural networks;speaker verification;embedding learning;model ensemble;Dense-Residual networks},
  doi={10.1109/ICASSP39728.2021.9413421},
  howpublished={https://ieeexplore.ieee.org/abstract/document/9413421/citations\#citations},
  note={Last Access 07/05/2025}
}

@article{knowledge_distillation,
  author = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen and Tao, Dacheng},
  year = {2020},
  month = {06},
  pages = {},
  title = {Knowledge Distillation: A Survey},
  doi = {10.48550/arXiv.2006.05525},
  howpublished={https://www.researchgate.net/publication/342094012\_Knowledge\_Distillation\_A\_Survey},
  note={Last Access 07/05/2025}
}

@misc{wu2023understandingint4quantizationtransformer,
      title={Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases}, 
      author={Xiaoxia Wu and Cheng Li and Reza Yazdani Aminabadi and Zhewei Yao and Yuxiong He},
      year={2023},
      eprint={2301.12017},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.12017},
      howpublished={https://arxiv.org/abs/2301.12017},
      note={Last Access 07/05/2025}
}

@misc{neural_network_theory,
  title={Neural Network Definition and Components},
  year={2024},
  howpublished={https://s.mriquestions.com/what-is-a-neural-network.html}

}

@misc{kws_rnn_based,
      title={Online Keyword Spotting with a Character-Level Recurrent Neural Network}, 
      author={Kyuyeon Hwang and Minjae Lee and Wonyong Sung},
      year={2015},
      eprint={1512.08903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1512.08903},
      howpublished={https://arxiv.org/abs/1512.08903} 
}

@misc{portaudio,
  title={PortAudio Cross-platform Audio I/O library},
  author={PortAudio Community},
  howpublished = {https://www.portaudio.com},
}
@article{FFTW,
	author = {Frigo, Matteo and Johnson, Steven~G.},
	journal = {Proceedings of the IEEE},
	note = {Special issue on ``Program Generation, Optimization, and Platform Adaptation''},
	number = 2,
	pages = {216--231},
	title = {The Design and Implementation of {FFTW3}},
	volume = 93,
	year = 2005,
  howpublished = {https://www.fftw.org},
}

@article{introduction_CNN,
  title={An introduction to convolutional neural networks},
  author={O'shea, Keiron and Nash, Ryan},
  journal={arXiv preprint arXiv:1511.08458},
  year={2015},
  howpublished={https://arxiv.org/abs/1511.08458},
}