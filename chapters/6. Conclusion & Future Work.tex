\chapter{Conclusion \& Future Work}
\label{cha:conclusion}

\section{Technical Limitations and Trade-offs}
\label{sec:technical limits and trade-offs}
The limited information regarding Syntiant's documentation limited the effective model testing because of the inability to effectively quantize the model to 4-int weights. The device would be optimal for such usages, but because of legal limitations and hardware limitations, such as the support of only DNN architectures, the SV capabilities are limited. However, the models obtained both convolution and distilled may be still used on other TinyML microcontrollers, in case they meet the size requirements and have an MFE block generator integrated in it, because the library and spectrogram computation occupies almost 20KB, which may not be optimal and with TinyML can exhaust memory, if an external memory is not used for dataset saving. So, introducing an SD card, even though it requires a longer elaboration time for the output, may be the best solution.\newline
During the discussion of the results, various trade-offs emerged in the choice of a model configuration with respect to the other:\newline
• Security vs User Experience: the choosing of the threshold is crucial in determining how a model satisfies the user objective. Choosing a too low threshold leads to having a high rate of both TP and FP, accepting all samples, but, on the other hand, choosing a too low one leads to having a high rate of TN and FN, accepting no samples.\newline 
• Model Size vs Complexity: Convolutional and dense layers, which are pretty different in the operations they do, were discussed in this thesis. The CNN performs more articulated and power requirement operations, but, on the other hand, they are small sized in training parameters terms, instead DNN performs easier operations, but they require more parameters to describe harder patterns, occupying more space.\newline
• Cosine Similarity vs Dataset Space: 3 methods were presented to handle reference d-vectors. Best-matching is the technique that requires N references that occupy xN times the space of geometrical median and mean techniques. However, the cosine similarity has higher values with the bestmatching, instead of the other two, because they are an average sample and not exactly a recorded sample.\newline

\section{Key Contributions and Future Directions}
\label{sec:key contributions}
This thesis provides a complete software pipeline of the system that is easily modifiable to integrate other audio neural networks. The models are optimized only in terms of performance; meanwhile, code quantization in GitHub repository\cite{thesisresources}, is proposed. It gives different results by Tensorflow version, so this feature was not dissected during the analysis. Compared with the solution TinySV proposed\cite{dvector_extractor_TinySV}\cite{dvector_extractor_code}, it was proposed a solution with 128-sized output was proposed to reduce the dimension of the model inspired by that solution. It turned out not being as good as the original, but still usable in the general-purpose case, but it is to avoid in the perfect precision case. From that a distillation method of the models was proposed to simply the operations computation proposing various alternatives compatible and deployable (if access to Syntiant SDK is granted) with Syntiant NDP101. The results of this work may still be used on other TinyML devices, and if some company can access the SDK, the work that was done may help in generating a compatible SV model directly on the device. In addition to this, it can be integrated in a bigger system that may unlock a door or give a precise response depending on the case and the threshold used. The code is ready and on paper according to the results obtained using this One-Time Training Approach with Speaker Verification on Syntiant NDP101 is possible, but as of now, because of means limitations cannot be tested. In the end, many focus in the future on this project should be exploring hybrid architectures that combine the efficiency of TinySV with larger models accuracy and precision and build a fully compatible Syntiant NDP101 integration. %The implementation as of now serves as a foundation that could be extended to support multi-modal authentication systems for one-precision requirement or general-purpose deployment. Other interesting in-depth may be digging in system's security aspects from spoofing attacks and noise robustness in edge environment scenario, actions that require a deploying first. 
\newpage