\chapter{KWS and SV Models}
\label{cha:training} 
\section{KWS Model}
\label{sec:kws deployment}
• Edge Impulse Integration - Model training and validation\newline
• C implementation, direct MFE computation on device\newline
• KWS model Deploying (Edge Impulse)\newline
Input (1600) → FC256 (ReLU) → FC256 (ReLU) → FC256 (ReLU) → Output (4, Softmax)\newline
Simulation (Weight extraction, target word, dataset), Real (model uploading and classification method)\newline

\newpage
PAGE 2
\newpage
PAGE 3
\newpage
\section{SV Model}
\label{sec:sv creation}
After creating the KWS model, the objective is creating a text-dependent Speaker Verification model, which requires only one train. This is known as ASV (Adaptive Speaker Verification), which relies on comparing the results of the model (d-vectors) with reference samples stored in system dataset, which have to be captured during inference phase. Speaker Verification is used in recognizing the identity of a user in a on-device learning context. To approach this way a large amount of data is required at first to train the model, performing a meticulous extraction of d-vectors to recognize patterns in user voice and possibly trying to minimize the required number of samples, maximizing the security recognition. A sample, because of text-depencendy, will correspond to a word said by one user and should compare only with its similar.\newline
The deployment of the model requires 3 caveats:\newline
1. Adapting directly on device, meaning that a new user should be able to enroll in SV application by providing samples of its voice in real time through the target device\newline
2. The algorithm has to operate in one-class manner and it should be able to learn to distinguish between the enrolled user and the others, only using the data from the dataset collected during inference\newline
3. To be fit in a TinyML device the considerations should be done in memory allocation depending on the device used, so the model should fit in Flash Memory\newline
To obtain the desired d-vector we should use a convolutional neural network.

• D-vector extraction - C port of Python CNN model \newline
• Database design for sample saving \newline
• Cosine similarity EER \newline
• Extend functionality to SV to be compatible with device (Python)\newline
Input (40x40) → Conv+BatchNorm layers → 256-dimensional d-vector \newline
Simulation (model-size, classification purpose, truncation explaination, verification methods (best-matching and mean-cosine)), Real (custom logic for verification)\newline

\subsection{Knowledge Distillation Training}

\subsection{Quantization of SV Model}
\label{sec:quantization}
• Float32 → Int8: Performance metrics showing minimal accuracy loss\newline
• Int8 → Int4: Challenges in maintaining model quality\newline
• Performance Comparison:\newline
    - Original CNN model vs. distilled DNN\newline
    - Full-precision vs. quantized implementations\newline
• Optimize neural network to be deployed on the device and verifying on simulation (Syntiant NDP101 and C-code)\newline\newline

\newpage
PAGE 5
\newpage
PAGE 6
\newpage 
PAGE 7
\newpage 
PAGE 8
\newpage